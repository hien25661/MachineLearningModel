{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1fQ813ETA4_1HYAEuvc_d1a_DLcQZL0rN",
      "authorship_tag": "ABX9TyMkuSCyMPkcVpNBBDMbc3AK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hien25661/learn-machine-learning-in-two-months/blob/master/ImageDirectionDetection(DNN).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Direction Detection\n",
        "- Problem : detect whether a given input image is correctly direction. \n",
        " + Positive sample: not rotated/flipped, correctly oriented, `label=1`. \n",
        " + Modified data to be a negative sample (flipped/rotated, `label=0`)."
      ],
      "metadata": {
        "id": "FugN9Rv9q9SA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mpuKTTP39A5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import datetime"
      ],
      "metadata": {
        "id": "AeNxA5x5vpxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.Load Dataset"
      ],
      "metadata": {
        "id": "GE3TKbCXrL_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading raw\n",
        "TRAIN_VAL_SPLIT = 0.15\n",
        "SEED = 1337\n",
        "IMG_SIZE = (256, 256)\n",
        "BATCH = 16"
      ],
      "metadata": {
        "id": "6z23xc_MrSyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.1 Pre-processing and Splitting\n",
        "\n",
        "#### a, Copy dataset"
      ],
      "metadata": {
        "id": "30qWN-w4wAu_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Image data preprocessing\n",
        "raw_dataset_train = tf.keras.utils.image_dataset_from_directory(\n",
        "    directory=\"/content/drive/MyDrive/MachineMags/ImageDirection/Data/Images\",\n",
        "    labels=None, crop_to_aspect_ratio=True, seed=SEED, image_size=IMG_SIZE,\n",
        "    validation_split=TRAIN_VAL_SPLIT, subset=\"training\", batch_size=BATCH)\n",
        "raw_dataset_val = tf.keras.utils.image_dataset_from_directory(\n",
        "    directory=\"/content/drive/MyDrive/MachineMags/ImageDirection/Data/Images\",\n",
        "    labels=None, crop_to_aspect_ratio=True, seed=SEED, image_size=IMG_SIZE,\n",
        "    validation_split=TRAIN_VAL_SPLIT, subset=\"validation\", batch_size=BATCH)"
      ],
      "metadata": {
        "id": "09EX5cbfwEHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### b, Splitting Dataset with label to each class"
      ],
      "metadata": {
        "id": "Enqw3J7qyi4E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def add_modifications_and_labels(image_batch):\n",
        "    batch_size = tf.shape(image_batch)[0]\n",
        "    print('batch_size:' + str(batch_size))\n",
        "    flipped_images = tf.image.flip_up_down(image_batch)\n",
        "\n",
        "    rotated_images = tf.image.rot90(image_batch, k=1)\n",
        "    print('rotated_images:' + str(rotated_images))\n",
        "    original_label = tf.ones([batch_size], dtype=tf.bool)\n",
        "    print('original_label:' + str(original_label))\n",
        "    modified_label = tf.zeros([batch_size], dtype=tf.bool)\n",
        "    print('modified_label:' + str(modified_label))\n",
        "\n",
        "    # Concatenate flipped/rotated images and original/modified labels to the dataset\n",
        "    image_batch = tf.concat([image_batch, flipped_images, rotated_images], 0)\n",
        "    labels = tf.cast(tf.concat([original_label, modified_label, modified_label], 0), tf.int32)\n",
        "\n",
        "    return image_batch, labels\n",
        "\n",
        "dataset_train = raw_dataset_train.map(add_modifications_and_labels, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "dataset_val = raw_dataset_val.map(add_modifications_and_labels, num_parallel_calls=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "HieTfQgtxbjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### b, Dataset visually"
      ],
      "metadata": {
        "id": "428qPWhtzwRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_images_and_labels(batch, predictions=None, stride=1, rows=4, cols=5):\n",
        "    plt.figure(figsize=(4 * cols, 4 * rows))\n",
        "    for images, labels in batch:\n",
        "        print(labels)\n",
        "        for i in range(rows * cols):\n",
        "            ax = plt.subplot(rows, cols, i + 1)\n",
        "            # display every nth image in the batch\n",
        "            idx = stride * i\n",
        "            image = images[idx]\n",
        "            label = labels[idx].numpy()\n",
        "            plt.imshow(image.numpy().astype(\"uint8\"))\n",
        "            title = \"Label: \" + str(label)\n",
        "            title_color = 'black'\n",
        "            if predictions is not None:\n",
        "                prediction = predictions[idx]\n",
        "                title += f\", Pred: {prediction:.2f}\"\n",
        "                error = np.abs(label - prediction)\n",
        "                if error > 0.5:\n",
        "                    title_color = 'red'\n",
        "            plt.title(title, color=title_color)\n",
        "            plt.axis(\"off\")\n",
        "        break\n",
        "    plt.show()\n",
        "\n",
        "plot_images_and_labels(dataset_train.take(1), stride=2)"
      ],
      "metadata": {
        "id": "sOXJTzLZ0DTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Train a Model\n",
        "### Use a base model trained on ImageNet without head and apply transfer learning to fine-tune for this problem. We will use DNN Model"
      ],
      "metadata": {
        "id": "O46VU9gA1d2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Pre-Trained Model EfficientNetB0\n",
        "base_model = tf.keras.applications.efficientnet.EfficientNetB0(weights=\"imagenet\", include_top=False,\n",
        "                                                               input_tensor=tf.keras.layers.Input(shape=(256, 256, 3)))"
      ],
      "metadata": {
        "id": "P3r2czBx1m4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = False\n",
        "# Data augmentation\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "])\n",
        "\n",
        "base_model.summary()\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    data_augmentation,\n",
        "    tf.keras.layers.GlobalMaxPooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=2e-4),\n",
        "    loss=tf.losses.BinaryCrossentropy(),\n",
        "    metrics=[tf.keras.metrics.BinaryAccuracy(), 'AUC', 'accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "3KBDOx7h6HSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training \n",
        "#### Train model with 30 epochs"
      ],
      "metadata": {
        "id": "SCc0FH-I63Cp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "\n",
        "epochs = 30;\n",
        "history = model.fit(\n",
        "    dataset_train,\n",
        "    validation_data=dataset_val,\n",
        "    epochs=epochs,\n",
        "    callbacks=[tensorboard_callback]\n",
        ")\n",
        "\n",
        "model.save('/content/drive/MyDrive/MachineMags/ImageDirection/img_orientation_detector_v1.h5')"
      ],
      "metadata": {
        "id": "_Ucf38xV6ZoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "UAr8GkUKCtfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs"
      ],
      "metadata": {
        "id": "NQWaiTrMDBF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction"
      ],
      "metadata": {
        "id": "uBaQctza9pfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sampled_images, sampled_labels = dataset_val.shuffle(1024).get_single_element()\n",
        "sampled_images, sampled_labels = dataset_val.unbatch().shuffle(1024).batch(64).take(1).get_single_element()\n",
        "\n",
        "\n",
        "print(len(sampled_images))\n",
        "print(len(sampled_labels))\n",
        "\n",
        "predictions = model.predict(sampled_images)\n",
        "#\n",
        "plot_images_and_labels([(sampled_images, sampled_labels)], predictions.squeeze(), stride=1, rows=5)"
      ],
      "metadata": {
        "id": "k7Bgff9m9o4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Evaluation\n",
        "### Get Final Accuracy value"
      ],
      "metadata": {
        "id": "ibMfdqOn8WMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res = model.evaluate(dataset_val)"
      ],
      "metadata": {
        "id": "cnX0KpNC-j_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Visually the Training Result, Evaluation Metric"
      ],
      "metadata": {
        "id": "GeurrFgB-Zar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v14MHB8d9Ecw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
