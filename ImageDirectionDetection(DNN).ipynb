{
nbformat: 4,
nbformat_minor: 0,
metadata: {
colab: {
private_outputs: true,
provenance: [ ],
mount_file_id: "1fQ813ETA4_1HYAEuvc_d1a_DLcQZL0rN",
authorship_tag: "ABX9TyMkuSCyMPkcVpNBBDMbc3AK",
include_colab_link: true
},
kernelspec: {
name: "python3",
display_name: "Python 3"
},
language_info: {
name: "python"
},
accelerator: "GPU",
gpuClass: "standard"
},
cells: [
{
cell_type: "markdown",
metadata: {
id: "view-in-github",
colab_type: "text"
},
source: [
"<a href="https://colab.research.google.com/github/hien25661/learn-machine-learning-in-two-months/blob/master/ImageDirectionDetection(DNN).ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>"
]
},
{
cell_type: "markdown",
source: [
"# Image Direction Detection
",
"- Problem : detect whether a given input image is correctly direction. 
",
" + Positive sample: not rotated/flipped, correctly oriented, `label=1`. 
",
" + Modified data to be a negative sample (flipped/rotated, `label=0`)."
],
metadata: {
id: "FugN9Rv9q9SA"
}
},
{
cell_type: "code",
source: [
"from google.colab import drive
",
"drive.mount('/content/drive')"
],
metadata: {
id: "mpuKTTP39A5E"
},
execution_count: null,
outputs: [ ]
},
{
cell_type: "code",
source: [
"import numpy as np
",
"import tensorflow as tf
",
"import matplotlib.pyplot as plt
",
"import os
",
"import datetime"
],
metadata: {
id: "AeNxA5x5vpxU"
},
execution_count: null,
outputs: [ ]
},
{
cell_type: "markdown",
source: [
"## 1.Load Dataset"
],
metadata: {
id: "GE3TKbCXrL_H"
}
},
{
cell_type: "code",
source: [
"# Loading raw
",
"TRAIN_VAL_SPLIT = 0.15
",
"SEED = 1337
",
"IMG_SIZE = (256, 256)
",
"BATCH = 16"
],
metadata: {
id: "6z23xc_MrSyy"
},
execution_count: null,
outputs: [ ]
},
{
cell_type: "markdown",
source: [
"###1.1 Pre-processing and Splitting
",
"
",
"#### a, Copy dataset"
],
metadata: {
id: "30qWN-w4wAu_"
}
},
{
cell_type: "code",
source: [
"# Image data preprocessing
",
"raw_dataset_train = tf.keras.utils.image_dataset_from_directory(
",
"    directory="/content/drive/MyDrive/MachineMags/ImageDirection/Data/Images",
",
"    labels=None, crop_to_aspect_ratio=True, seed=SEED, image_size=IMG_SIZE,
",
"    validation_split=TRAIN_VAL_SPLIT, subset="training", batch_size=BATCH)
",
"raw_dataset_val = tf.keras.utils.image_dataset_from_directory(
",
"    directory="/content/drive/MyDrive/MachineMags/ImageDirection/Data/Images",
",
"    labels=None, crop_to_aspect_ratio=True, seed=SEED, image_size=IMG_SIZE,
",
"    validation_split=TRAIN_VAL_SPLIT, subset="validation", batch_size=BATCH)"
],
metadata: {
id: "09EX5cbfwEHI"
},
execution_count: null,
outputs: [ ]
},
{
cell_type: "markdown",
source: [
"#### b, Splitting Dataset with label to each class"
],
metadata: {
id: "Enqw3J7qyi4E"
}
},
{
cell_type: "code",
source: [
"@tf.function
",
"def add_modifications_and_labels(image_batch):
",
"    batch_size = tf.shape(image_batch)[0]
",
"    print('batch_size:' + str(batch_size))
",
"    flipped_images = tf.image.flip_up_down(image_batch)
",
"
",
"    rotated_images = tf.image.rot90(image_batch, k=1)
",
"    print('rotated_images:' + str(rotated_images))
",
"    original_label = tf.ones([batch_size], dtype=tf.bool)
",
"    print('original_label:' + str(original_label))
",
"    modified_label = tf.zeros([batch_size], dtype=tf.bool)
",
"    print('modified_label:' + str(modified_label))
",
"
",
"    # Concatenate flipped/rotated images and original/modified labels to the dataset
",
"    image_batch = tf.concat([image_batch, flipped_images, rotated_images], 0)
",
"    labels = tf.cast(tf.concat([original_label, modified_label, modified_label], 0), tf.int32)
",
"
",
"    return image_batch, labels
",
"
",
"dataset_train = raw_dataset_train.map(add_modifications_and_labels, num_parallel_calls=tf.data.AUTOTUNE)
",
"dataset_val = raw_dataset_val.map(add_modifications_and_labels, num_parallel_calls=tf.data.AUTOTUNE)"
],
metadata: {
id: "HieTfQgtxbjM"
},
execution_count: null,
outputs: [ ]
},
{
cell_type: "markdown",
source: [
"#### b, Dataset visually"
],
metadata: {
id: "428qPWhtzwRn"
}
},
{
cell_type: "code",
source: [
"def plot_images_and_labels(batch, predictions=None, stride=1, rows=4, cols=5):
",
"    plt.figure(figsize=(4 * cols, 4 * rows))
",
"    for images, labels in batch:
",
"        print(labels)
",
"        for i in range(rows * cols):
",
"            ax = plt.subplot(rows, cols, i + 1)
",
"            # display every nth image in the batch
",
"            idx = stride * i
",
"            image = images[idx]
",
"            label = labels[idx].numpy()
",
"            plt.imshow(image.numpy().astype("uint8"))
",
"            title = "Label: " + str(label)
",
"            title_color = 'black'
",
"            if predictions is not None:
",
"                prediction = predictions[idx]
",
"                title += f", Pred: {prediction:.2f}"
",
"                error = np.abs(label - prediction)
",
"                if error > 0.5:
",
"                    title_color = 'red'
",
"            plt.title(title, color=title_color)
",
"            plt.axis("off")
",
"        break
",
"    plt.show()
",
"
",
"plot_images_and_labels(dataset_train.take(1), stride=2)"
],
metadata: {
id: "sOXJTzLZ0DTq"
},
execution_count: null,
outputs: [ ]
},
{
cell_type: "markdown",
source: [
"# 2. Train a Model
",
"### Use a base model trained on ImageNet without head and apply transfer learning to fine-tune for this problem. We will use DNN Model"
],
metadata: {
id: "O46VU9gA1d2q"
}
},
{
cell_type: "code",
source: [
"# Load Pre-Trained Model EfficientNetB0
",
"base_model = tf.keras.applications.efficientnet.EfficientNetB0(weights="imagenet", include_top=False,
",
"                                                               input_tensor=tf.keras.layers.Input(shape=(256, 256, 3)))"
],
metadata: {
id: "P3r2czBx1m4m"
},
execution_count: null,
outputs: [ ]
},
{
cell_type: "code",
source: [
"base_model.trainable = False
",
"# Data augmentation
",
"data_augmentation = tf.keras.Sequential([
",
"    tf.keras.layers.RandomFlip("horizontal"),
",
"])
",
"
",
"base_model.summary()
",
"
",
"model = tf.keras.Sequential([
",
"    base_model,
",
"    data_augmentation,
",
"    tf.keras.layers.GlobalMaxPooling2D(),
",
"    tf.keras.layers.Flatten(),
",
"    tf.keras.layers.Dense(128, activation='relu'),
",
"    tf.keras.layers.BatchNormalization(),
",
"    tf.keras.layers.Dropout(0.3),
",
"    tf.keras.layers.Dense(64, activation='relu'),
",
"    tf.keras.layers.BatchNormalization(),
",
"    tf.keras.layers.Dropout(0.3),
",
"    tf.keras.layers.Dense(32, activation='relu'),
",
"    tf.keras.layers.Dropout(0.3),
",
"    tf.keras.layers.Dense(1, activation='sigmoid')
",
"])
",
"
",
"model.compile(
",
"    optimizer=tf.keras.optimizers.Adam(learning_rate=2e-4),
",
"    loss=tf.losses.BinaryCrossentropy(),
",
"    metrics=[tf.keras.metrics.BinaryAccuracy(), 'AUC', 'accuracy'])
",
"model.summary()"
],
metadata: {
id: "3KBDOx7h6HSJ"
},
execution_count: null,
outputs: [ ]
},
{
cell_type: "markdown",
source: [
"## Model Training 
",
"#### Train model with 30 epochs"
],
metadata: {
id: "SCc0FH-I63Cp"
}
},
{
cell_type: "code",
source: [
"logdir = os.path.join("logs", datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))
",
"tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)
",
"
",
"epochs = 30;
",
"history = model.fit(
",
"    dataset_train,
",
"    validation_data=dataset_val,
",
"    epochs=epochs,
",
"    callbacks=[tensorboard_callback]
",
")
",
"
",
"model.save('/content/drive/MyDrive/MachineMags/ImageDirection/img_orientation_detector_v1.h5')"
],
metadata: {
id: "_Ucf38xV6ZoI"
},
execution_count: null,
outputs: [ ]
},
{
cell_type: "code",
source: [
"%load_ext tensorboard"
],
metadata: {
id: "UAr8GkUKCtfk"
},
execution_count: null,
outputs: [ ]
},
{
cell_type: "code",
source: [
"%tensorboard --logdir logs"
],
metadata: {
id: "NQWaiTrMDBF9"
},
execution_count: null,
outputs: [ ]
},
{
cell_type: "markdown",
source: [
"## Prediction"
],
metadata: {
id: "uBaQctza9pfK"
}
},
{
cell_type: "code",
source: [
"#sampled_images, sampled_labels = dataset_val.shuffle(1024).get_single_element()
",
"sampled_images, sampled_labels = dataset_val.unbatch().shuffle(1024).batch(64).take(1).get_single_element()
",
"
",
"
",
"print(len(sampled_images))
",
"print(len(sampled_labels))
",
"
",
"predictions = model.predict(sampled_images)
",
"#
",
"plot_images_and_labels([(sampled_images, sampled_labels)], predictions.squeeze(), stride=1, rows=5)"
],
metadata: {
id: "k7Bgff9m9o4n"
},
execution_count: null,
outputs: [ ]
},
{
cell_type: "markdown",
source: [
"# 3. Evaluation
",
"### Get Final Accuracy value"
],
metadata: {
id: "ibMfdqOn8WMl"
}
},
{
cell_type: "code",
source: [
"res = model.evaluate(dataset_val)"
],
metadata: {
id: "cnX0KpNC-j_x"
},
execution_count: null,
outputs: [ ]
},
{
cell_type: "markdown",
source: [
"###Visually the Training Result, Evaluation Metric"
],
metadata: {
id: "GeurrFgB-Zar"
}
},
{
cell_type: "code",
source: [
"acc = history.history['accuracy']
",
"val_acc = history.history['val_accuracy']
",
"
",
"loss = history.history['loss']
",
"val_loss = history.history['val_loss']
",
"
",
"epochs_range = range(epochs)
",
"
",
"plt.figure(figsize=(8, 8))
",
"plt.subplot(1, 2, 1)
",
"plt.plot(epochs_range, acc, label='Training Accuracy')
",
"plt.plot(epochs_range, val_acc, label='Validation Accuracy')
",
"plt.legend(loc='lower right')
",
"plt.title('Training and Validation Accuracy')
",
"
",
"plt.subplot(1, 2, 2)
",
"plt.plot(epochs_range, loss, label='Training Loss')
",
"plt.plot(epochs_range, val_loss, label='Validation Loss')
",
"plt.legend(loc='upper right')
",
"plt.title('Training and Validation Loss')
",
"plt.show()"
],
metadata: {
id: "v14MHB8d9Ecw"
},
execution_count: null,
outputs: [ ]
}
]
}
